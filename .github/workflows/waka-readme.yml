name: Waka Readme

on:
  schedule:
    # Runs at 12am UTC every day
    - cron: '0 0 * * *'
  workflow_dispatch:

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

permissions:
  contents: write
  pull-requests: write

jobs:
  update:
    name: Update README stats via PR
    runs-on: ubuntu-latest
    permissions:
      contents: write
      pull-requests: write
      actions: write
    steps:
      - name: Checkout main
        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v6.0.1
        with:
          ref: main
          token: ${{ secrets.WAKA_PAT || github.token }}

      - name: Fetch WakaTime stats and update README
        env:
          WAKATIME_API_KEY: ${{ secrets.WAKATIME_API_KEY }}
        run: |
          set -euo pipefail

          # Fetch stats from WakaTime API
          AUTH=$(echo -n "$WAKATIME_API_KEY" | base64)
          
          # Use summaries endpoint with date range for real-time data (bypasses cache)
          END_DATE=$(date -u +%Y-%m-%d)
          START_DATE=$(date -u -d '7 days ago' +%Y-%m-%d)
          
          echo "Fetching WakaTime data from $START_DATE to $END_DATE"
          
          SUMMARIES=$(curl -sf -H "Authorization: Basic $AUTH" \
            "https://wakatime.com/api/v1/users/current/summaries?start=$START_DATE&end=$END_DATE")
          
          if [ -z "$SUMMARIES" ]; then
            echo "Failed to fetch WakaTime summaries"
            exit 1
          fi
          
          # Aggregate summaries into stats format
          STATS=$(echo "$SUMMARIES" | jq '{
            data: {
              total_seconds_including_other_language: [.data[].grand_total.total_seconds] | add,
              human_readable_total: ([.data[].grand_total.total_seconds] | add | . / 3600 | floor | tostring) + " hrs " + (([.data[].grand_total.total_seconds] | add % 3600 / 60 | floor | tostring) + " mins"),
              human_readable_daily_average: ([.data[].grand_total.total_seconds] | add / 7 / 3600 | floor | tostring) + " hrs " + (([.data[].grand_total.total_seconds] | add / 7 % 3600 / 60 | floor | tostring) + " mins"),
              languages: ([.data[].languages] | flatten | group_by(.name) | map({name: .[0].name, total_seconds: ([.[].total_seconds] | add), percent: 0, text: ""}) | sort_by(.total_seconds) | reverse | .[0:5] | to_entries | map(.value + {percent: (.value.total_seconds / ([..] | .total_seconds) | add) * 100 | floor, text: ((.value.total_seconds / 3600 | floor | tostring) + " hrs " + ((.value.total_seconds % 3600 / 60 | floor | tostring) + " mins"))})),
              editors: ([.data[].editors] | flatten | group_by(.name) | map({name: .[0].name, total_seconds: ([.[].total_seconds] | add), percent: 0, text: ""}) | sort_by(.total_seconds) | reverse | .[0:3] | to_entries | map(.value + {percent: (.value.total_seconds / ([..] | .total_seconds) | add) * 100 | floor, text: ((.value.total_seconds / 3600 | floor | tostring) + " hrs " + ((.value.total_seconds % 3600 / 60 | floor | tostring) + " mins"))})),
              operating_systems: ([.data[].operating_systems] | flatten | group_by(.name) | map({name: .[0].name, total_seconds: ([.[].total_seconds] | add), percent: 0, text: ""}) | sort_by(.total_seconds) | reverse | .[0:3] | to_entries | map(.value + {percent: (.value.total_seconds / ([..] | .total_seconds) | add) * 100 | floor, text: ((.value.total_seconds / 3600 | floor | tostring) + " hrs " + ((.value.total_seconds % 3600 / 60 | floor | tostring) + " mins"))})),
              projects: ([.data[].projects] | flatten | group_by(.name) | map({name: .[0].name, total_seconds: ([.[].total_seconds] | add), percent: 0, text: ""}) | sort_by(.total_seconds) | reverse | .[0:5] | to_entries | map(.value + {percent: (.value.total_seconds / ([..] | .total_seconds) | add) * 100 | floor, text: ((.value.total_seconds / 3600 | floor | tostring) + " hrs " + ((.value.total_seconds % 3600 / 60 | floor | tostring) + " mins"))})),
              categories: ([.data[].categories] | flatten | group_by(.name) | map({name: .[0].name, total_seconds: ([.[].total_seconds] | add), percent: 0, text: ""}) | sort_by(.total_seconds) | reverse | .[0:5] | to_entries | map(.value + {percent: (.value.total_seconds / ([..] | .total_seconds) | add) * 100 | floor, text: ((.value.total_seconds / 3600 | floor | tostring) + " hrs " + ((.value.total_seconds % 3600 / 60 | floor | tostring) + " mins"))})),
              best_day: (.data | max_by(.grand_total.total_seconds) | {date: .range.date, text: ((.grand_total.total_seconds / 3600 | floor | tostring) + " hrs " + ((.grand_total.total_seconds % 3600 / 60 | floor | tostring) + " mins"))}),
              start: .data[0].range.date,
              end: .data[-1].range.date,
              timezone: .data[0].range.timezone
            }
          }')
          
          # Debug: Log key stats totals
          TOTAL_SECONDS=$(echo "$STATS" | jq -r '.data.total_seconds_including_other_language // 0')
          echo "Debug: Total seconds from API: $TOTAL_SECONDS ($(echo "scale=2; $TOTAL_SECONDS / 3600" | bc) hours)"
          
          echo "Debug: Languages breakdown"
          echo "$STATS" | jq -r '(.data.languages // [])[] | "- \(.name // "unknown"): \(.text // "0 secs") (\(.percent // 0)% / \(.total_seconds // 0) sec)"'
          
          echo "Debug: Editors breakdown"
          echo "$STATS" | jq -r '(.data.editors // [])[] | "- \(.name // "unknown"): \(.text // "0 secs") (\(.percent // 0)% / \(.total_seconds // 0) sec)"'
          
          echo "Debug: Operating systems breakdown"
          echo "$STATS" | jq -r '(.data.operating_systems // [])[] | "- \(.name // "unknown"): \(.text // "0 secs") (\(.percent // 0)% / \(.total_seconds // 0) sec)"'
          
          echo "Debug: Projects breakdown"
          echo "$STATS" | jq -r '(.data.projects // [])[] | "- \(.name // "unknown"): \(.text // "0 secs") (\(.percent // 0)% / \(.total_seconds // 0) sec)"'
          
          echo "Debug: Categories breakdown"
          echo "$STATS" | jq -r '(.data.categories // [])[] | "- \(.name // "unknown"): \(.text // "0 secs") (\(.percent // 0)% / \(.total_seconds // 0) sec)"'

          # Extract data using jq
          TOTAL=$(echo "$STATS" | jq -r '.data.human_readable_total // "0 hrs"')
          DAILY_AVG=$(echo "$STATS" | jq -r '.data.human_readable_daily_average // "0 hrs"')
          BEST_DAY_DATE=$(echo "$STATS" | jq -r '.data.best_day.date // "N/A"')
          BEST_DAY_TIME=$(echo "$STATS" | jq -r '.data.best_day.text // "0 hrs"')
          RANGE_START=$(echo "$STATS" | jq -r '.data.start // ""' | cut -d'T' -f1)
          RANGE_END=$(echo "$STATS" | jq -r '.data.end // ""' | cut -d'T' -f1)
          TIMEZONE=$(echo "$STATS" | jq -r '.data.timezone // "UTC"')
          
          # Fetch GitHub language stats (non-fork repos with language info)
          GITHUB_LANGUAGES=$(curl -sf -H "Authorization: Bearer ${{ github.token }}" \
            "https://api.github.com/users/reesey275/repos?per_page=100&type=owner" | \
            jq -r '[.[] | select(.fork == false and .language != null) | .language] | group_by(.) | map({language: .[0], count: length}) | sort_by(-.count) | .[:5]')
          
          TOTAL_REPOS=$(echo "$GITHUB_LANGUAGES" | jq -r 'map(.count) | add // 0')

          # Build progress bar function (using braille blocks like athul/waka-readme)
          make_bar() {
            local pct=$1
            local blocks="â£€â£„â£¤â£¦â£¶â£·â£¿"
            local bar=""
            local full_blocks=$((pct * 25 / 100))
            local remainder=$(((pct * 25 % 100) * 7 / 100))

            for ((i=0; i<full_blocks; i++)); do
              bar+="${blocks:6:1}"
            done
            if [ $full_blocks -lt 25 ] && [ $remainder -gt 0 ]; then
              bar+="${blocks:$remainder:1}"
              full_blocks=$((full_blocks + 1))
            fi
            for ((i=full_blocks; i<25; i++)); do
              bar+="${blocks:0:1}"
            done
            echo "$bar"
          }

          # Format time with padding
          pad_time() {
            printf "%-16s" "$1"
          }

          pad_name() {
            printf "%-20s" "$1"
          }

          pad_pct() {
            printf "%6.2f %%" "$1"
          }

          # Generate languages section
          LANGUAGES=""
          while IFS= read -r line; do
            name=$(echo "$line" | jq -r '.name')
            text=$(echo "$line" | jq -r '.text')
            pct=$(echo "$line" | jq -r '.percent')
            bar=$(make_bar "${pct%.*}")
            LANGUAGES+="$(pad_name "$name")$(pad_time "$text")$bar   $(pad_pct "$pct")"$'\n'
          done < <(echo "$STATS" | jq -c '.data.languages[:5][]')

          # Generate editors section
          EDITORS=""
          while IFS= read -r line; do
            name=$(echo "$line" | jq -r '.name')
            text=$(echo "$line" | jq -r '.text')
            pct=$(echo "$line" | jq -r '.percent')
            bar=$(make_bar "${pct%.*}")
            EDITORS+="$(pad_name "$name")$(pad_time "$text")$bar   $(pad_pct "$pct")"$'\n'
          done < <(echo "$STATS" | jq -c '.data.editors[:3][]')

          # Generate OS section
          OS_STATS=""
          while IFS= read -r line; do
            name=$(echo "$line" | jq -r '.name')
            text=$(echo "$line" | jq -r '.text')
            pct=$(echo "$line" | jq -r '.percent')
            bar=$(make_bar "${pct%.*}")
            OS_STATS+="$(pad_name "$name")$(pad_time "$text")$bar   $(pad_pct "$pct")"$'\n'
          done < <(echo "$STATS" | jq -c '.data.operating_systems[:3][]')

          # Generate projects section
          PROJECTS=""
          while IFS= read -r line; do
            name=$(echo "$line" | jq -r '.name')
            text=$(echo "$line" | jq -r '.text')
            pct=$(echo "$line" | jq -r '.percent')
            bar=$(make_bar "${pct%.*}")
            PROJECTS+="$(pad_name "$name")$(pad_time "$text")$bar   $(pad_pct "$pct")"$'\n'
          done < <(echo "$STATS" | jq -c '.data.projects[:5][]')

          # Generate categories section (AI Coding, Coding, Writing Docs, etc.)
          CATEGORIES=""
          while IFS= read -r line; do
            name=$(echo "$line" | jq -r '.name')
            text=$(echo "$line" | jq -r '.text')
            pct=$(echo "$line" | jq -r '.percent')
            bar=$(make_bar "${pct%.*}")
            CATEGORIES+="$(pad_name "$name")$(pad_time "$text")$bar   $(pad_pct "$pct")"$'\n'
          done < <(echo "$STATS" | jq -c '.data.categories[:5][]')
          
          # Generate day-of-week section
          DAYS_OF_WEEK=""
          declare -A day_names=([0]="Sunday" [1]="Monday" [2]="Tuesday" [3]="Wednesday" [4]="Thursday" [5]="Friday" [6]="Saturday")
          declare -a day_data
          for i in {0..6}; do
            day_info=$(echo "$STATS" | jq -r ".data.days[$i] // empty")
            if [ -n "$day_info" ]; then
              day_data[$i]="$day_info"
            fi
          done
          
          # Find most productive day (integer comparison with proper handling)
          max_seconds=0
          max_day=""
          for i in {0..6}; do
            if [ -n "${day_data[$i]:-}" ]; then
              seconds=$(echo "${day_data[$i]}" | jq -r '.total_seconds // 0' | cut -d'.' -f1)
              if [ "${seconds:-0}" -gt "$max_seconds" ]; then
                max_seconds=$seconds
                max_day="${day_names[$i]}"
              fi
            fi
          done
          
          # Default to Sunday if no data available
          if [ -z "$max_day" ]; then
            max_day="Sunday"
          fi
          
          # Build day-of-week stats (Monday-Sunday order for readability)
          for i in {1..6} 0; do
            if [ -n "${day_data[$i]:-}" ]; then
              name="${day_names[$i]}"
              text=$(echo "${day_data[$i]}" | jq -r '.text // "0 secs"')
              pct=$(echo "${day_data[$i]}" | jq -r '.percent // 0')
              # Safe decimal removal: handle whole numbers and decimals
              pct_int="${pct%.*}"
              if [ -z "$pct_int" ]; then pct_int=0; fi
              bar=$(make_bar "$pct_int")
              DAYS_OF_WEEK+="$(pad_name "$name")$(pad_time "$text")$bar   $(pad_pct "$pct")"$'\n'
            fi
          done
          
          # Generate language repos section from GitHub (with division by zero guard)
          LANGUAGE_REPOS=""
          most_used_lang=""
          if [ -n "${GITHUB_LANGUAGES:-}" ] && [ "$GITHUB_LANGUAGES" != "null" ] && [ "$TOTAL_REPOS" -gt 0 ]; then
            most_used_lang=$(echo "$GITHUB_LANGUAGES" | jq -r '.[0].language // "Unknown"')
            while IFS= read -r line; do
              lang=$(echo "$line" | jq -r '.language')
              count=$(echo "$line" | jq -r '.count')
              if [ "${TOTAL_REPOS:-0}" -eq 0 ]; then
                pct=0
              else
                pct=$(echo "scale=2; $count * 100 / $TOTAL_REPOS" | bc)
              fi
              # Safe decimal removal
              pct_int="${pct%.*}"
              if [ -z "$pct_int" ]; then pct_int=0; fi
              bar=$(make_bar "$pct_int")
              LANGUAGE_REPOS+="$(pad_name "$lang")$(printf "%-16s" "$count repos")$bar   $(pad_pct "$pct")"$'\n'
            done < <(echo "$GITHUB_LANGUAGES" | jq -c '.[]')
          fi

          # Get current timestamp
          UPDATED=$(date -u "+%Y-%m-%d %H:%M:%S UTC")

          # Build the full stats section
          STATS_CONTENT="
          \`\`\`txt
          ðŸŒ Time Zone: ${TIMEZONE}
          ðŸ“… ${RANGE_START} - ${RANGE_END}
          â±ï¸ Total: ${TOTAL}  |  Daily Avg: ${DAILY_AVG}  |  Best Day: ${BEST_DAY_DATE} (${BEST_DAY_TIME})

          â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

          ðŸ’» Languages

          ${LANGUAGES}
          â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

          ðŸ› ï¸  Editors

          ${EDITORS}
          â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

          ðŸ–¥ï¸  Operating Systems

          ${OS_STATS}
          â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

          ðŸ“ Projects

          ${PROJECTS}
          â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

          ðŸ“Š Categories

          ${CATEGORIES}
          â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
          \`\`\`

          _Last updated: ${UPDATED}_"

          # Clean up the content (remove leading spaces from heredoc)
          STATS_CONTENT=$(echo "$STATS_CONTENT" | sed 's/^          //')

          # Update README between markers
          awk -v content="$STATS_CONTENT" '
            /<!--START_SECTION:waka-->/ { print; print content; skip=1; next }
            /<!--END_SECTION:waka-->/ { skip=0 }
            !skip { print }
          ' README.md > README.tmp && mv README.tmp README.md

      - name: Create or update PR and enable auto-merge
        env:
          GH_TOKEN: ${{ secrets.WAKA_PAT || github.token }}
        run: |
          set -euo pipefail

          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"

          BASE_BRANCH="main"
          HEAD_BRANCH="waka-readme"
          REPO="$GITHUB_REPOSITORY"

          git fetch origin "$HEAD_BRANCH" || true
          git checkout -B "$HEAD_BRANCH"

          CURRENT_BRANCH="$(git rev-parse --abbrev-ref HEAD)"
          if [ "$CURRENT_BRANCH" != "$HEAD_BRANCH" ]; then
            echo "ERROR: Expected to be on $HEAD_BRANCH but on $CURRENT_BRANCH"
            exit 1
          fi

          git add README.md

          if git diff --staged --quiet; then
            echo "No changes to commit"
            exit 0
          fi

          git commit -m "chore(waka): update weekly development stats"

          git fetch origin "$BASE_BRANCH" --depth=1 || true
          if git diff --quiet "origin/$BASE_BRANCH"...HEAD; then
            echo "No diff vs $BASE_BRANCH; skipping PR."
            echo "No PR needed; deleting remote branch $HEAD_BRANCH to avoid orphaned branch."
            git push origin HEAD:"$HEAD_BRANCH" --force-with-lease
            git push origin --delete "$HEAD_BRANCH" || echo "Warning: Failed to delete remote branch $HEAD_BRANCH"
            exit 0
          fi

          git fetch origin "$HEAD_BRANCH" || true
          git push origin HEAD:"$HEAD_BRANCH" --force-with-lease

          # Create PR body in temp file (printf pattern avoids YAML heredoc parsing issues)
          TEMP_BODY="$(mktemp -t "waka_pr_body.XXXXXX")"
          cleanup() { rm -f "$TEMP_BODY"; }
          trap cleanup EXIT
          
          TIMESTAMP="$(date -u '+%Y-%m-%d %H:%M:%S UTC')"
          printf '%s\n\n%s\n%s\n%s\n%s\n%s\n%s\n\n%s\n' \
            "Automated WakaTime stats update from GitHub Actions." \
            "**Stats Include:**" \
            "- Languages breakdown" \
            "- Editors used" \
            "- Operating systems" \
            "- Active projects" \
            "- Activity categories (AI Coding, Coding, Docs)" \
            "_Updated: ${TIMESTAMP}_" \
            > "$TEMP_BODY"

          PR_NUMBER=$(gh pr list --repo "$REPO" --head "$HEAD_BRANCH" --state open --json number -q '.[0].number' || true)

          if [ -z "${PR_NUMBER:-}" ] || [ "$PR_NUMBER" = "null" ]; then
            PR_URL=$(gh pr create --repo "$REPO" --base "$BASE_BRANCH" --head "$HEAD_BRANCH" \
              --title "chore(waka): update waka stats" \
              --body-file "$TEMP_BODY")
            PR_NUMBER=$(gh pr view "$PR_URL" --repo "$REPO" --json number -q .number)
          else
            gh pr edit "$PR_NUMBER" --repo "$REPO" --title "chore(waka): update waka stats" --body-file "$TEMP_BODY"
          fi

          if [ -z "${PR_NUMBER:-}" ]; then
            echo "ERROR: Failed to create/find PR for $HEAD_BRANCH -> $BASE_BRANCH"
            exit 1
          fi

          STATE=$(gh pr view --repo "$REPO" "$PR_NUMBER" --json state -q .state)
          if [ "$STATE" != "OPEN" ]; then
            echo "ERROR: PR #$PR_NUMBER is not OPEN (state=$STATE). Head branch may have been deleted or PR closed."
            exit 1
          fi

          # Explicitly dispatch required workflow checks on the PR branch
          # This prevents "Expected â€” Waiting" status from bot token limitations
          echo "Dispatching required workflows on $HEAD_BRANCH branch..."
          if ! gh workflow run lint.yml --repo "$REPO" --ref "$HEAD_BRANCH"; then
            echo "WARNING: Failed to dispatch lint workflow (workflow_dispatch may not be configured)"
          fi
          if ! gh workflow run docs-quality.yml --repo "$REPO" --ref "$HEAD_BRANCH"; then
            echo "WARNING: Failed to dispatch docs-quality workflow (workflow_dispatch may not be configured)"
          fi

          # Enable auto-merge (checks will be verified by GitHub before merging)
          gh pr merge "$PR_NUMBER" --repo "$REPO" --auto --squash --delete-branch
          echo "Auto-merge requested for PR #$PR_NUMBER"
          echo "Checks dispatched and will be verified before merge."
